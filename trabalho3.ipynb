{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742545c1-c72d-4a61-91f9-5beb7f96e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from PIL import Image, ImageFilter, ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f0d6f6-8e39-441b-b038-ea94964743db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(input_path):\n",
    "    \"\"\"\n",
    "    Read images in the input_path, \n",
    "    save image, patient of each image and the class (group/labels)\n",
    "    \n",
    "    Params: \n",
    "    input_path = path to the original images \n",
    "    \n",
    "    Return:\n",
    "    images = list of all images\n",
    "    labels = list with class for each image\n",
    "    \"\"\"\n",
    "   \n",
    "    # Lists to save images, patients and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Browse input path\n",
    "    for class_dir in os.listdir(input_path):\n",
    "        class_path = os.path.join(input_path, class_dir)\n",
    "\n",
    "        # If it is a directory \n",
    "        if os.path.isdir(class_path):      \n",
    "\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                image = cv.imread(image_path)\n",
    "\n",
    "                # Append image, patient id and class to list\n",
    "                images.append(image)            \n",
    "                labels.append(class_dir)    \n",
    "                \n",
    "    df = pd.DataFrame({'image': images, 'label': labels})\n",
    "    \n",
    "    # Create a LabelEncoder object\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['label'])\n",
    "    df['label'] = le.transform(df['label'])\n",
    "    \n",
    "    df = df.reset_index()\n",
    "                \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0977a7-420e-4534-b391-89de12fba1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_images(\"/home/vsa/ufpr/cb/ufpr-bioinspired-comp/dataset/train\")\n",
    "x_test, y_test = read_images(\"/home/vsa/ufpr/cb/ufpr-bioinspired-comp/dataset/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ab401f-3e54-4e1e-b373-137e04a0d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_grayscale(data):\n",
    "    \n",
    "    ft_gray = []\n",
    "    \n",
    "    for image in data:\n",
    "        \n",
    "        shape = image.shape\n",
    "        \n",
    "        gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        ft_gray.append(np.reshape(gray, (shape[0]*shape[1])))\n",
    "    \n",
    "    return ft_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fee49a2-9352-4fd8-b516-ed8e472a0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean_channels(data):\n",
    "    \n",
    "    ft_mean = []\n",
    "\n",
    "    for image in data:\n",
    "\n",
    "        shape = image.shape\n",
    "        matrix = np.zeros(shape) \n",
    "        #print(shape, matrix.shape, end=' ')\n",
    "        matrix = np.mean(image, axis=2)\n",
    "        \n",
    "        ft_mean.append(np.reshape(matrix, (shape[0]*shape[1]))) \n",
    "        #print(np.reshape(matrix, (shape[0], shape[1])).shape)\n",
    "            \n",
    "    return ft_mean     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "91d9de71-88fe-455d-8281-cdb788a01f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "def extract_edges_len(data):\n",
    "    \n",
    "    ft_edges_len = []\n",
    "    \n",
    "    for image in data:\n",
    "        \n",
    "#         shape = image.shape\n",
    "#         img = image.reshape((-1,3))\n",
    "#         img = np.float32(img)\n",
    "\n",
    "#         criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "#         K = 5\n",
    "#         attempts=10\n",
    "\n",
    "#         ret, label, center = cv.kmeans(tw, K, None, criteria, attempts,cv.KMEANS_PP_CENTERS)\n",
    "#         center = np.uint8(center)\n",
    "#         res = center[label.flatten()]\n",
    "#         segmented = res.reshape((shape))      \n",
    "     \n",
    "#         scale = 1\n",
    "#         delta = 0\n",
    "#         ddepth = cv.CV_16S\n",
    "\n",
    "#         grad_x = cv.Sobel(segmented, ddepth, 1, 0, ksize=3, scale=scale, delta=delta, borderType=cv.BORDER_DEFAULT)\n",
    "#         grad_y = cv.Sobel(segmented, ddepth, 0, 1, ksize=3, scale=scale, delta=delta, borderType=cv.BORDER_DEFAULT)\n",
    "\n",
    "#         abs_grad_x = cv.convertScaleAbs(grad_x)\n",
    "#         abs_grad_y = cv.convertScaleAbs(grad_y)\n",
    "\n",
    "#         grad = cv.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "\n",
    "#         pil = Image.fromarray(grad)\n",
    "        \n",
    "#         edges = pil.filter(ImageFilter.FIND_EDGES)\n",
    "#         edges = np.asarray(edges)\n",
    "        \n",
    "        feature.canny(cv.cvtColor(image, cv.COLOR_BGR2GRAY))\n",
    "        # Extract the edge pixels\n",
    "        edge_pixels = edges.nonzero()\n",
    "\n",
    "        # Calculate the edge length for each edge pixel\n",
    "        edge_lengths = []\n",
    "        \n",
    "        for i, j in zip(*edge_pixels):\n",
    "            # Get the coordinates of the current pixel\n",
    "            x, y = j, i\n",
    "\n",
    "            # Check if there's a next pixel in the edge segment\n",
    "            if x > 0:\n",
    "                # Get the coordinates of the next pixel\n",
    "                x2 = edge_pixels[0][x - 1]\n",
    "                y2 = edge_pixels[1][x - 1]\n",
    "            else:\n",
    "                # Handle the edge case where there's no next pixel\n",
    "                x2 = edge_pixels[0][-1]\n",
    "                y2 = edge_pixels[1][-1]\n",
    "\n",
    "            # Calculate the distance between the two pixels\n",
    "            distance = np.sqrt((x2 - x)**2 + (y2 - y)**2)\n",
    "\n",
    "            # Add the distance to the list of edge lengths\n",
    "            edge_lengths.append(distance)\n",
    "            \n",
    "        ft_edges_len.append(edge_lengths) \n",
    "      \n",
    "    return ft_edges_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9918c7-6b66-4eba-a6f1-3c380e75da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_gray = extract_grayscale(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0c8930-52ab-4813-a924-f060655712d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_mean = extract_mean_channels(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9411c-2f44-461c-a359-c887423e8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_edges_len = extract_edges_len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c2c043-cb34-4785-98b0-cb7bb1340560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ft_gray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a6c670-ca58-4482-ac9e-a54dcbf23091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ft_mean.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(ft_gray, 'ft_gray.joblib')\n",
    "dump(ft_mean, 'ft_mean.joblib')\n",
    "dump(ft_edges_len, 'ft_edges_len.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3bc68-d3af-4eec-8663-879ec4d85841",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_gray = load('ft_gray.joblib')\n",
    "ft_mean = load('ft_mean.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8c9f0c64-2cc1-40d4-a28d-4fab83f389d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52458a-f402-4de8-bc95-63e7e328717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale Pixel Values done\n",
    "# Mean Pixel Value of Channels\n",
    "# length of the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb0c19-8249-44f0-b25e-ca8ac12224a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53630ae9-a418-4d69-aa3f-96b76454c382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
