{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "742545c1-c72d-4a61-91f9-5beb7f96e669",
      "metadata": {
        "id": "742545c1-c72d-4a61-91f9-5beb7f96e669"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump, load\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import dump, load\n",
        "from PIL import Image, ImageFilter, ImageChops\n",
        "from skimage import feature\n",
        "from random import random\n",
        "from random import uniform\n",
        "from sklearn import svm\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada0c82c-1fd4-4ce4-b121-4809d54a8951",
      "metadata": {
        "id": "ada0c82c-1fd4-4ce4-b121-4809d54a8951"
      },
      "source": [
        "### Read images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "65f0d6f6-8e39-441b-b038-ea94964743db",
      "metadata": {
        "id": "65f0d6f6-8e39-441b-b038-ea94964743db"
      },
      "outputs": [],
      "source": [
        "def read_images(input_path):\n",
        "    \"\"\"\n",
        "    Read images in the input_path,\n",
        "    save image, patient of each image and the class (group/labels)\n",
        "\n",
        "    Params:\n",
        "    input_path = path to the original images\n",
        "\n",
        "    Return:\n",
        "    images = list of all images\n",
        "    labels = list with class for each image\n",
        "    \"\"\"\n",
        "\n",
        "    # Lists to save images, patients and labels\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Browse input path\n",
        "    for class_dir in os.listdir(input_path):\n",
        "        class_path = os.path.join(input_path, class_dir)\n",
        "\n",
        "        # If it is a directory\n",
        "        if os.path.isdir(class_path):\n",
        "\n",
        "            for image_file in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Append image, patient id and class to list\n",
        "                images.append(image)\n",
        "                labels.append(class_dir)\n",
        "\n",
        "    return (images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "577f2cfd-e006-4f9e-9e14-16ac2e66e494",
      "metadata": {
        "id": "577f2cfd-e006-4f9e-9e14-16ac2e66e494"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "#wget https://www.inf.ufpr.br/vsa20/dataset.tar.gz\n",
        "tar -xf /content/dataset.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "612301d9-ec64-494a-b58f-3325b56de4bf",
      "metadata": {
        "id": "612301d9-ec64-494a-b58f-3325b56de4bf"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b62c8a-ff2e-4bc9-abf0-bb91a36a353c",
      "metadata": {
        "id": "90b62c8a-ff2e-4bc9-abf0-bb91a36a353c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "28b45775-5303-41f5-b1f9-6d2d5d002f35",
      "metadata": {
        "id": "28b45775-5303-41f5-b1f9-6d2d5d002f35"
      },
      "source": [
        "### Extract features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a6ab401f-3e54-4e1e-b373-137e04a0d124",
      "metadata": {
        "id": "a6ab401f-3e54-4e1e-b373-137e04a0d124"
      },
      "outputs": [],
      "source": [
        "# Extract grayscale features\n",
        "def extract_grayscale(data):\n",
        "\n",
        "    ft_gray = []\n",
        "\n",
        "    for image in data:\n",
        "\n",
        "        shape = image.shape\n",
        "        ft_gray.append(np.reshape(image, (shape[0]*shape[1])))\n",
        "\n",
        "    return ft_gray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "91d9de71-88fe-455d-8281-cdb788a01f80",
      "metadata": {
        "id": "91d9de71-88fe-455d-8281-cdb788a01f80"
      },
      "outputs": [],
      "source": [
        "# Extract feature: length of the edges\n",
        "def extract_edges_len(data):\n",
        "\n",
        "    ft_edges_len = []\n",
        "\n",
        "    for image in data:\n",
        "\n",
        "        edges = feature.canny(image)\n",
        "\n",
        "        # Extract the edge pixels\n",
        "        edge_pixels = edges.nonzero()\n",
        "\n",
        "        # Calculate the edge length for each edge pixel\n",
        "        edge_lengths = []\n",
        "\n",
        "        for i, j in zip(*edge_pixels):\n",
        "            # Get the coordinates of the current pixel\n",
        "            x, y = j, i\n",
        "\n",
        "            # Check if there's a next pixel in the edge segment\n",
        "            if x > 0:\n",
        "                # Get the coordinates of the next pixel\n",
        "                x2 = edge_pixels[0][x - 1]\n",
        "                y2 = edge_pixels[1][x - 1]\n",
        "            else:\n",
        "                # Handle the edge case where there's no next pixel\n",
        "                x2 = edge_pixels[0][-1]\n",
        "                y2 = edge_pixels[1][-1]\n",
        "\n",
        "            # Calculate the distance between the two pixels\n",
        "            distance = np.sqrt((x2 - x)**2 + (y2 - y)**2)\n",
        "\n",
        "            # Add the distance to the list of edge lengths\n",
        "            edge_lengths.append(distance)\n",
        "\n",
        "        ft_edges_len.append(edge_lengths)\n",
        "\n",
        "    return ft_edges_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe93ec2-3614-440d-ab27-13033cd1d854",
      "metadata": {
        "id": "efe93ec2-3614-440d-ab27-13033cd1d854"
      },
      "outputs": [],
      "source": [
        "# Extract features: curvature of the edges\n",
        "from scipy.interpolate import CubicBezier\n",
        "def extract_edges_curv(data):\n",
        "    edges = feature.canny(image)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "922ed439-2534-4d35-960b-eac7d18b0c3b",
      "metadata": {
        "id": "922ed439-2534-4d35-960b-eac7d18b0c3b"
      },
      "outputs": [],
      "source": [
        "# Extract features: LBP\n",
        "\n",
        "def extract_lbp(data, eps=1e-7, points=24, radius=8):\n",
        "\n",
        "    ft_lbp = []\n",
        "\n",
        "    for image in data:\n",
        "\n",
        "        lbp = feature.local_binary_pattern(image,\n",
        "                                           points,\n",
        "                                           radius,\n",
        "                                           method=\"uniform\")\n",
        "\n",
        "        (hist, _) = np.histogram(lbp.ravel(),\n",
        "                                 bins = np.arange(0, points + 3),\n",
        "                                                 range=(0, points + 2))\n",
        "\n",
        "        # normalize the histogram\n",
        "        hist = hist.astype(\"float\")\n",
        "        hist /= (hist.sum() + eps)\n",
        "\n",
        "        ft_lbp.append(hist)\n",
        "\n",
        "    # return the histogram of Local Binary Patterns\n",
        "    return ft_lbp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = read_images(\"/content/dataset/train\")"
      ],
      "metadata": {
        "id": "U1ungD3DAMEi"
      },
      "id": "U1ungD3DAMEi",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "af9918c7-6b66-4eba-a6f1-3c380e75da83",
      "metadata": {
        "id": "af9918c7-6b66-4eba-a6f1-3c380e75da83"
      },
      "outputs": [],
      "source": [
        "ft_gray = extract_grayscale(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "40c9411c-2f44-461c-a359-c887423e8252",
      "metadata": {
        "id": "40c9411c-2f44-461c-a359-c887423e8252"
      },
      "outputs": [],
      "source": [
        "ft_edges_len = extract_edges_len(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e327e85e-aa05-49fd-a4a6-743b794455ea",
      "metadata": {
        "id": "e327e85e-aa05-49fd-a4a6-743b794455ea"
      },
      "outputs": [],
      "source": [
        "ft_lbp = extract_lbp(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "153d4d04-2d14-498c-a206-2174c80fc9b3",
      "metadata": {
        "id": "153d4d04-2d14-498c-a206-2174c80fc9b3"
      },
      "source": [
        "Get feature names and table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a86e39b9-133e-4707-9b99-62cc64ebf611",
      "metadata": {
        "id": "a86e39b9-133e-4707-9b99-62cc64ebf611"
      },
      "outputs": [],
      "source": [
        "max_edges_count = 0\n",
        "for sample in ft_edges_len:\n",
        "    edges_count = len(sample)\n",
        "\n",
        "    if edges_count > max_edges_count:\n",
        "        max_edges_count = edges_count\n",
        "\n",
        "names = []\n",
        "\n",
        "names_gray = [f'gray{i}' for i in range(len(ft_gray[0]))]\n",
        "names_edges = [f'edges{i}' for i in range(max_edges_count)]\n",
        "names_lbp = [f'lbp{i}' for i in range(len(ft_lbp[0]))]\n",
        "\n",
        "names.append(names_gray)\n",
        "names.append(names_edges)\n",
        "names.append(names_lbp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8feb0c19-8249-44f0-b25e-ca8ac12224a3",
      "metadata": {
        "id": "8feb0c19-8249-44f0-b25e-ca8ac12224a3"
      },
      "outputs": [],
      "source": [
        "df_gray = pd.DataFrame(ft_gray, columns = names_gray)\n",
        "df_edges = pd.DataFrame(ft_edges_len, columns = names_edges)\n",
        "df_lbp = pd.DataFrame(ft_lbp, columns = names_lbp)\n",
        "\n",
        "df = pd.concat([df_gray, df_edges, df_lbp], axis = 1)\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "df['label'] = y_train\n",
        "le = LabelEncoder()\n",
        "le.fit(df['label'])\n",
        "df['label'] = le.transform(df['label'])\n",
        "\n",
        "df = df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/df.csv\")"
      ],
      "metadata": {
        "id": "gChmr4qIFLvN"
      },
      "id": "gChmr4qIFLvN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dbf342b4-a6b7-4158-97fe-db25ea259ac4",
      "metadata": {
        "id": "dbf342b4-a6b7-4158-97fe-db25ea259ac4"
      },
      "source": [
        "### PSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd62f46-7314-464d-82dc-1b6bb3bc4cfa",
      "metadata": {
        "id": "fbd62f46-7314-464d-82dc-1b6bb3bc4cfa"
      },
      "outputs": [],
      "source": [
        "# numero total de features disponiveis\n",
        "max_feature_id = 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of dimensions\n",
        "# i.e. feature number for each particle\n",
        "n_dimensions = 3\n",
        "\n",
        "# initial particles position\n",
        "# since we can't use the same feature repeated,\n",
        "# the initial position has features ranging from 0 to n_features\n",
        "initial_pos = []\n",
        "for i in range(n_dimensions):\n",
        "    initial_pos.append(i)\n",
        "\n",
        "# min and max values for the features\n",
        "# 0 is the id for the first feature,\n",
        "# and max_feature_id is the id for the last feature\n",
        "bounds = [(0, max_feature_id)]*n_dimensions\n",
        "\n"
      ],
      "metadata": {
        "id": "2Yt3GgM4E_fl"
      },
      "id": "2Yt3GgM4E_fl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(x):\n",
        "    total=0\n",
        "    for i in range(len(x)):\n",
        "        total+=x[i]**2\n",
        "    return total"
      ],
      "metadata": {
        "id": "JKk2obENFCv1"
      },
      "id": "JKk2obENFCv1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Particle:\n",
        "    def __init__(self, initial_pos):\n",
        "\n",
        "        self.position_i = []          # particle position, i.e. features\n",
        "        self.velocity_i = []          # particle velocity\n",
        "        self.pos_best_i = []          # best position individual\n",
        "        self.err_best_i = -1          # best error individual\n",
        "        self.err_i = -1               # error individual\n",
        "\n",
        "        # intiialize position\n",
        "        self.position_i = initial_pos\n",
        "        # intiialize velocity as values between -1 and 1\n",
        "        for i in range(0, n_dimensions):\n",
        "            self.velocity_i.append(uniform(-1,1))\n",
        "\n",
        "    # evaluate current fitness\n",
        "    def evaluate(self, costFunc):\n",
        "        self.err_i = costFunc(self.position_i)\n",
        "\n",
        "        # check to see if the current position is an individual best\n",
        "        if self.err_i < self.err_best_i or self.err_best_i == -1:\n",
        "            self.pos_best_i = self.position_i.copy()\n",
        "            self.err_best_i = self.err_i\n",
        "\n",
        "    # update new particle velocity\n",
        "    def update_velocity(self, pos_best_g, w, c1, c2):\n",
        "\n",
        "        # constant inertia weight (how much to weigh the previous velocity)\n",
        "        # cognitive constant (influences pbest)\n",
        "        # social constant (influences gbest)\n",
        "\n",
        "        for i in range(0, n_dimensions):\n",
        "\n",
        "            # non-deterministic values to prevent particles\n",
        "            # from getting stuck in local optima\n",
        "            r1 = random()\n",
        "            r2 = random()\n",
        "\n",
        "            # update cognitive and social\n",
        "            vel_cognitive = c1 * r1 * (self.pos_best_i[i] - self.position_i[i])\n",
        "            vel_social = c2 * r2 * (pos_best_g[i] - self.position_i[i])\n",
        "\n",
        "            self.velocity_i[i] = w * self.velocity_i[i] + vel_cognitive + vel_social\n",
        "\n",
        "    # update the particle position based off new velocity updates\n",
        "    def update_position(self,bounds):\n",
        "        for i in range(0, n_dimensions):\n",
        "            self.position_i[i] = round(self.position_i[i] + self.velocity_i[i])\n",
        "\n",
        "            # adjust maximum position if necessary\n",
        "            if self.position_i[i] > bounds[i][1]:\n",
        "                self.position_i[i] = bounds[i][1]\n",
        "\n",
        "            # adjust minimum position if neseccary\n",
        "            if self.position_i[i] < bounds[i][0]:\n",
        "                self.position_i[i] = bounds[i][0]\n",
        "\n",
        "\n",
        "def minimize(cost_function, initial_pos, bounds, n_particles,\n",
        "             n_dimensions, maxiter, verbose=False):\n",
        "\n",
        "    err_best_g = -1                   # best error for group\n",
        "    pos_best_g = []                   # best position for group\n",
        "\n",
        "    # establish the swarm\n",
        "    swarm = []\n",
        "    for i in range(0, n_particles):\n",
        "        swarm.append(Particle(initial_pos, n_dimensions))\n",
        "\n",
        "    # begin optimization loop\n",
        "    i = 0\n",
        "    while i < maxiter:\n",
        "        if verbose: print(f'iter: {i:>4d}, best solution: {err_best_g:10.6f}')\n",
        "\n",
        "        # cycle through particles in swarm and evaluate fitness\n",
        "        for j in range(0, n_particles):\n",
        "            swarm[j].evaluate(cost_function)\n",
        "\n",
        "            # determine if current particle is the best (globally)\n",
        "            if swarm[j].err_i < err_best_g or err_best_g == -1:\n",
        "                pos_best_g = swarm[j].position_i\n",
        "                err_best_g = float(swarm[j].err_i)\n",
        "\n",
        "        # cycle through swarm and update velocities and position\n",
        "        for j in range(0, n_particles):\n",
        "            swarm[j].update_velocity(pos_best_g)\n",
        "            swarm[j].update_position(bounds)\n",
        "\n",
        "        i+=1\n",
        "\n",
        "    # print final results\n",
        "    if verbose:\n",
        "        print('\\nFINAL SOLUTION:')\n",
        "        print(f'   > {pos_best_g}')\n",
        "        print(f'   > {err_best_g}\\n')\n",
        "\n",
        "    return err_best_g, pos_best_g"
      ],
      "metadata": {
        "id": "iu9ziHVVFBgk"
      },
      "id": "iu9ziHVVFBgk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minimize(sphere, initial, bounds, num_particles=15, maxiter=30, verbose=True)"
      ],
      "metadata": {
        "id": "Gf6DErIEFH7k"
      },
      "id": "Gf6DErIEFH7k",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sklearn-env",
      "language": "python",
      "name": "sklearn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}