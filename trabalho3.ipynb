{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742545c1-c72d-4a61-91f9-5beb7f96e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from PIL import Image, ImageFilter, ImageChops\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0c82c-1fd4-4ce4-b121-4809d54a8951",
   "metadata": {},
   "source": [
    "### Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f0d6f6-8e39-441b-b038-ea94964743db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(input_path):\n",
    "    \"\"\"\n",
    "    Read images in the input_path, \n",
    "    save image, patient of each image and the class (group/labels)\n",
    "    \n",
    "    Params: \n",
    "    input_path = path to the original images \n",
    "    \n",
    "    Return:\n",
    "    images = list of all images\n",
    "    labels = list with class for each image\n",
    "    \"\"\"\n",
    "   \n",
    "    # Lists to save images, patients and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Browse input path\n",
    "    for class_dir in os.listdir(input_path):\n",
    "        class_path = os.path.join(input_path, class_dir)\n",
    "\n",
    "        # If it is a directory \n",
    "        if os.path.isdir(class_path):      \n",
    "\n",
    "            for image_file in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_file)\n",
    "\n",
    "                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Append image, patient id and class to list\n",
    "                images.append(image)            \n",
    "                labels.append(class_dir)    \n",
    "                              \n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0977a7-420e-4534-b391-89de12fba1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_images(\"/home/vsa/ufpr/cb/ufpr-bioinspired-computing/dataset/train\")\n",
    "#x_test, y_test = read_images(\"/home/vsa/ufpr/cb/ufpr-bioinspired-computing/dataset/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612301d9-ec64-494a-b58f-3325b56de4bf",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f2cfd-e006-4f9e-9e14-16ac2e66e494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b62c8a-ff2e-4bc9-abf0-bb91a36a353c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28b45775-5303-41f5-b1f9-6d2d5d002f35",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ab401f-3e54-4e1e-b373-137e04a0d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract grayscale features\n",
    "def extract_grayscale(data):\n",
    "    \n",
    "    ft_gray = []\n",
    "    \n",
    "    for image in data:\n",
    "        \n",
    "        shape = image.shape\n",
    "        ft_gray.append(np.reshape(image, (shape[0]*shape[1])))\n",
    "    \n",
    "    return ft_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d9de71-88fe-455d-8281-cdb788a01f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature: length of the edges\n",
    "def extract_edges_len(data):\n",
    "    \n",
    "    ft_edges_len = []\n",
    "    \n",
    "    for image in data:\n",
    "        \n",
    "        edges = feature.canny(image)\n",
    "        \n",
    "        # Extract the edge pixels\n",
    "        edge_pixels = edges.nonzero()\n",
    "\n",
    "        # Calculate the edge length for each edge pixel\n",
    "        edge_lengths = []\n",
    "        \n",
    "        for i, j in zip(*edge_pixels):\n",
    "            # Get the coordinates of the current pixel\n",
    "            x, y = j, i\n",
    "\n",
    "            # Check if there's a next pixel in the edge segment\n",
    "            if x > 0:\n",
    "                # Get the coordinates of the next pixel\n",
    "                x2 = edge_pixels[0][x - 1]\n",
    "                y2 = edge_pixels[1][x - 1]\n",
    "            else:\n",
    "                # Handle the edge case where there's no next pixel\n",
    "                x2 = edge_pixels[0][-1]\n",
    "                y2 = edge_pixels[1][-1]\n",
    "\n",
    "            # Calculate the distance between the two pixels\n",
    "            distance = np.sqrt((x2 - x)**2 + (y2 - y)**2)\n",
    "\n",
    "            # Add the distance to the list of edge lengths\n",
    "            edge_lengths.append(distance)\n",
    "            \n",
    "        ft_edges_len.append(edge_lengths) \n",
    "      \n",
    "    return ft_edges_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe93ec2-3614-440d-ab27-13033cd1d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features: curvature of the edges\n",
    "from scipy.interpolate import CubicBezier\n",
    "def extract_edges_curv(data):\n",
    "    edges = feature.canny(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "922ed439-2534-4d35-960b-eac7d18b0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features: LBP\n",
    "\n",
    "def extract_lbp(data, eps=1e-7, points=24, radius=8):\n",
    "    \n",
    "    ft_lbp = []\n",
    "    \n",
    "    for image in data:\n",
    "        \n",
    "        lbp = feature.local_binary_pattern(image,\n",
    "                                           points,\n",
    "                                           radius,\n",
    "                                           method=\"uniform\")\n",
    "\n",
    "        (hist, _) = np.histogram(lbp.ravel(), \n",
    "                                 bins = np.arange(0, points + 3),\n",
    "                                                 range=(0, points + 2))\n",
    "\n",
    "        # normalize the histogram\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "        \n",
    "        ft_lbp.append(hist)\n",
    "\n",
    "    # return the histogram of Local Binary Patterns\n",
    "    return ft_lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9918c7-6b66-4eba-a6f1-3c380e75da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_gray = extract_grayscale(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c9411c-2f44-461c-a359-c887423e8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_edges_len = extract_edges_len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e327e85e-aa05-49fd-a4a6-743b794455ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_lbp = extract_lbp(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a6c670-ca58-4482-ac9e-a54dcbf23091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ft_mean.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(ft_gray, 'ft_gray.joblib')\n",
    "dump(ft_edges_len, 'ft_edges_len.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3bc68-d3af-4eec-8663-879ec4d85841",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_gray = load('ft_gray.joblib')\n",
    "ft_edges_len = load('ft_mean.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9f0c64-2cc1-40d4-a28d-4fab83f389d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_gray = load('ft_gray.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104c180-7cc7-4fc9-9a3d-21816c7eff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(ft_edges_len, 'ft_edges_len.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52458a-f402-4de8-bc95-63e7e328717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale Pixel Values done\n",
    "# length of the edges done\n",
    "# curvature of edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d4d04-2d14-498c-a206-2174c80fc9b3",
   "metadata": {},
   "source": [
    "Get feature names and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a32d64-dcb1-4cda-aa49-0dd392007e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edges_count = 0\n",
    "for sample in ft_edges_len:\n",
    "    edges_count = len(sample)\n",
    "    \n",
    "    if edges_count > max_edges_count:\n",
    "        max_edges_count = edges_count\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a86e39b9-133e-4707-9b99-62cc64ebf611",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "names_gray = [f'gray{i}' for i in range(len(ft_gray[0]))]\n",
    "names_edges = [f'edges{i}' for i in range(max_edges_count)]\n",
    "names_lbp = [f'lbp{i}' for i in range(len(ft_lbp[0]))]\n",
    "names.append(names_gray)\n",
    "names.append(names_edges)\n",
    "names.append(names_lbp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e275d5-5279-41e8-ad1e-b9aed14e94f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8e182-97ed-420f-b9a8-36392df4e723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb0c19-8249-44f0-b25e-ca8ac12224a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'image': images, 'label': labels})\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "le.fit(df['label'])\n",
    "df['label'] = le.transform(df['label'])\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf342b4-a6b7-4158-97fe-db25ea259ac4",
   "metadata": {},
   "source": [
    "### PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd62f46-7314-464d-82dc-1b6bb3bc4cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
